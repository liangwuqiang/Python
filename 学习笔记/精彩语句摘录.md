# << 精彩语句摘录 >>

### 迭代结果传入函数,返回列表
htmls = [func(url, str(index) + ".html") for index, url in enumerate(urllist)]

### 特定位置插入
html_template = """
<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"></head><body>
{content}
</body></html>
"""
html = html_template.format(content="<p>string</p>")

### 文本中插入
pattern = "(<img .*?src=\")(.*?)(\")"
def func(m):
    rtn = m.group(1) + "http://www.liaoxuefeng.com/" + m.group(2) + m.group(3)
    return rtn
html = re.compile(pattern).sub(func, html)

### 布局title和content
center_tag = soup.new_tag("center")
title_tag = soup.new_tag('h1')
title_tag.string = title
center_tag.insert(1, title_tag)
content.insert(0, center_tag)

### 伪装
req.add_header('User-Agent', 'Mozilla/6.0 (iPhone; CPU iPhone OS 8_0 like Mac OS X) AppleWebKit/536.26 (KHTML, like Gecko) Version/8.0 Mobile/10A5376e Safari/8536.25')

    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_5) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87'


### 进化
pattern = "(<img .*?src=\")(.*?)(\")"
def func(m):
    if not m.group(3).startswith("http"):
       rtn = m.group(1) + "http://www.liaoxuefeng.com" + m.group(2) + m.group(3)
       return rtn
    else:
       return m.group(1)+m.group(2)+m.group(3)
     
### 进化
except Exception as e:
    # print(e)
    logging.error("解析错误", exc_info=True)

### 在文件中输出调试信息
scrapy crawl spder_name -s LOG_FILE=scrapy.log

### 函数返回迭代生成器
def parse(self,response):
    for site in sites:
        item['title'] = title
        item['link'] = link
        yield item
我的理解是,程序开辟了一个yield的空间,循环一次就将item传送进来,完事之后,函数返回yield.

### 截取域名地址
domain = '{uri.scheme}://{uri.netloc}'.format(uri=urlparse(url))
