
<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="UTF-8">
</head><body>

    <div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<center><h3>数据收集(StatsCollection)</h3></center>
<div itemprop="articleBody">
<div class="section" id="stats-collection">
<span id="topics-stats"></span><h1>数据收集(Stats Collection)<a class="headerlink" href="#stats-collection" title="永久链接至标题"></a></h1>
<p>Scrapy提供了方便的收集数据的机制。数据以key/value方式存储，值大多是计数值。
该机制叫做数据收集器(Stats Collector)，可以通过
<a class="reference internal" href="api.html#topics-api-crawler"><span class="std std-ref">Crawler API</span></a> 的属性 <a class="reference internal" href="api.html#scrapy.crawler.Crawler.stats" title="scrapy.crawler.Crawler.stats"><code class="xref py py-attr docutils literal"><span class="pre">stats</span></code></a>
来使用。在下面的章节
<a class="reference internal" href="#topics-stats-usecases"><span class="std std-ref">常见数据收集器使用方法</span></a> 将给出例子来说明。</p>
<p>无论数据收集(stats collection)开启或者关闭，数据收集器永远都是可用的。
因此您可以import进自己的模块并使用其API(增加值或者设置新的状态键(stat keys))。
该做法是为了简化数据收集的方法: 您不应该使用超过一行代码来收集您的spider，Scrpay扩展或任何您使用数据收集器代码里头的状态。</p>
<p>数据收集器的另一个特性是(在启用状态下)很高效，(在关闭情况下)非常高效(几乎察觉不到)。</p>
<p>数据收集器对每个spider保持一个状态表。当spider启动时，该表自动打开，当spider关闭时，自动关闭。</p>
<div class="section" id="topics-stats-usecases">
<span id="id1"></span><h2>常见数据收集器使用方法<a class="headerlink" href="#topics-stats-usecases" title="永久链接至标题"></a></h2>
<p>通过 <a class="reference internal" href="api.html#scrapy.crawler.Crawler.stats" title="scrapy.crawler.Crawler.stats"><code class="xref py py-attr docutils literal"><span class="pre">stats</span></code></a> 属性来使用数据收集器。
下面是在扩展中使用状态的例子:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">ExtensionThatAccessStats</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">stats</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">stats</span> <span class="o">=</span> <span class="n">stats</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_crawler</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">crawler</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">cls</span><span class="p">(</span><span class="n">crawler</span><span class="o">.</span><span class="n">stats</span><span class="p">)</span>
</pre></div>
</div>
<p>设置数据:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">stats</span><span class="o">.</span><span class="n">set_value</span><span class="p">(</span><span class="s1">'hostname'</span><span class="p">,</span> <span class="n">socket</span><span class="o">.</span><span class="n">gethostname</span><span class="p">())</span>
</pre></div>
</div>
<p>增加数据值:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">stats</span><span class="o">.</span><span class="n">inc_value</span><span class="p">(</span><span class="s1">'pages_crawled'</span><span class="p">)</span>
</pre></div>
</div>
<p>当新的值比原来的值大时设置数据:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">stats</span><span class="o">.</span><span class="n">max_value</span><span class="p">(</span><span class="s1">'max_items_scraped'</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
<p>当新的值比原来的值小时设置数据:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="n">stats</span><span class="o">.</span><span class="n">min_value</span><span class="p">(</span><span class="s1">'min_free_memory_percent'</span><span class="p">,</span> <span class="n">value</span><span class="p">)</span>
</pre></div>
</div>
<p>获取数据:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">get_value</span><span class="p">(</span><span class="s1">'pages_crawled'</span><span class="p">)</span>
<span class="go">8</span>
</pre></div>
</div>
<p>获取所有数据:</p>
<div class="highlight-default"><div class="highlight"><pre><span></span><span class="gp">&gt;&gt;&gt; </span><span class="n">stats</span><span class="o">.</span><span class="n">get_stats</span><span class="p">()</span>
<span class="go">{'pages_crawled': 1238, 'start_time': datetime.datetime(2009, 7, 14, 21, 47, 28, 977139)}</span>
</pre></div>
</div>
</div>
<div class="section" id="id2">
<h2>可用的数据收集器<a class="headerlink" href="#id2" title="永久链接至标题"></a></h2>
<p>除了基本的 <code class="xref py py-class docutils literal"><span class="pre">StatsCollector</span></code> ，Scrapy也提供了基于 <code class="xref py py-class docutils literal"><span class="pre">StatsCollector</span></code> 的数据收集器。
您可以通过 <a class="reference internal" href="settings.html#std:setting-STATS_CLASS"><code class="xref std std-setting docutils literal"><span class="pre">STATS_CLASS</span></code></a> 设置来选择。默认使用的是
<code class="xref py py-class docutils literal"><span class="pre">MemoryStatsCollector</span></code> 。</p>
<span class="target" id="module-scrapy.statscol"></span><div class="section" id="memorystatscollector">
<h3>MemoryStatsCollector<a class="headerlink" href="#memorystatscollector" title="永久链接至标题"></a></h3>
<dl class="class">
<dt id="scrapy.statscol.MemoryStatsCollector">
<em class="property">class </em><code class="descclassname">scrapy.statscol.</code><code class="descname">MemoryStatsCollector</code><a class="headerlink" href="#scrapy.statscol.MemoryStatsCollector" title="永久链接至目标"></a></dt>
<dd><p>一个简单的数据收集器。其在spider运行完毕后将其数据保存在内存中。数据可以通过
<a class="reference internal" href="#scrapy.statscol.MemoryStatsCollector.spider_stats" title="scrapy.statscol.MemoryStatsCollector.spider_stats"><code class="xref py py-attr docutils literal"><span class="pre">spider_stats</span></code></a> 属性访问。该属性是一个以spider名字为键(key)的字典。</p>
<p>这是Scrapy的默认选择。</p>
<dl class="attribute">
<dt id="scrapy.statscol.MemoryStatsCollector.spider_stats">
<code class="descname">spider_stats</code><a class="headerlink" href="#scrapy.statscol.MemoryStatsCollector.spider_stats" title="永久链接至目标"></a></dt>
<dd><p>保存了每个spider最近一次爬取的状态的字典(dict)。该字典以spider名字为键，值也是字典。</p>
</dd></dl>
</dd></dl>
</div>
<div class="section" id="dummystatscollector">
<h3>DummyStatsCollector<a class="headerlink" href="#dummystatscollector" title="永久链接至标题"></a></h3>
<dl class="class">
<dt id="scrapy.statscol.DummyStatsCollector">
<em class="property">class </em><code class="descclassname">scrapy.statscol.</code><code class="descname">DummyStatsCollector</code><a class="headerlink" href="#scrapy.statscol.DummyStatsCollector" title="永久链接至目标"></a></dt>
<dd><p>该数据收集器并不做任何事情但非常高效(因为什么都不做(写文档的人真调皮o(╯□╰)o))。
您可以通过设置 <a class="reference internal" href="settings.html#std:setting-STATS_CLASS"><code class="xref std std-setting docutils literal"><span class="pre">STATS_CLASS</span></code></a> 启用这个收集器，来关闭数据收集，提高效率。
不过，数据收集的性能负担相较于Scrapy其他的处理(例如分析页面)来说是非常小的。</p>
</dd></dl>
</div>
</div>
</div>
<h2>
            讨论
            <a class="headerlink" href="#discuss" title="永久链接至标题"></a>
</h2>
<div id="disqus_thread"></div>
</div>
<div class="articleComments">
</div>
</div>
    
</body></html>
