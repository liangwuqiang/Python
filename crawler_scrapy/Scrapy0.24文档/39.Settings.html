
<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="UTF-8">
</head><body>

    <div class="document" itemscope="itemscope" itemtype="http://schema.org/Article" role="main">
<center><h3>Settings</h3></center>
<div itemprop="articleBody">
<div class="section" id="settings">
<span id="topics-settings"></span><h1>Settings<a class="headerlink" href="#settings" title="永久链接至标题"></a></h1>
<p>Scrapy设定(settings)提供了定制Scrapy组件的方法。您可以控制包括核心(core)，插件(extension)，pipeline及spider组件。</p>
<p>设定为代码提供了提取以key-value映射的配置值的的全局命名空间(namespace)。
设定可以通过下面介绍的多种机制进行设置。</p>
<p>设定(settings)同时也是选择当前激活的Scrapy项目的方法(如果您有多个的话)。</p>
<p>内置设定列表请参考 <a class="reference internal" href="#topics-settings-ref"><span class="std std-ref">内置设定参考手册</span></a> 。</p>
<div class="section" id="designating-the-settings">
<h2>指定设定(Designating the settings)<a class="headerlink" href="#designating-the-settings" title="永久链接至标题"></a></h2>
<p>当您使用Scrapy时，您需要声明您所使用的设定。这可以通过使用环境变量:
<code class="docutils literal"><span class="pre">SCRAPY_SETTINGS_MODULE</span></code> 来完成。</p>
<p><code class="docutils literal"><span class="pre">SCRAPY_SETTINGS_MODULE</span></code> 必须以Python路径语法编写, 如 <code class="docutils literal"><span class="pre">myproject.settings</span></code> 。
注意，设定模块应该在 Python <a class="reference external" href="http://docs.python.org/2/tutorial/modules.html#the-module-search-path">import search path</a> 中。</p>
</div>
<div class="section" id="populating-the-settings">
<h2>获取设定值(Populating the settings)<a class="headerlink" href="#populating-the-settings" title="永久链接至标题"></a></h2>
<p>设定可以通过多种方式设置，每个方式具有不同的优先级。
下面以优先级降序的方式给出方式列表:</p>
<blockquote>
<div><ol class="arabic simple">
<li>命令行选项(Command line Options)(最高优先级)</li>
<li>项目设定模块(Project settings module)</li>
<li>命令默认设定模块(Default settings per-command)</li>
<li>全局默认设定(Default global settings) (最低优先级)</li>
</ol>
</div></blockquote>
<p>这些设定(settings)由scrapy内部很好的进行了处理，不过您仍可以使用API调用来手动处理。
详情请参考 <a class="reference internal" href="api.html#topics-api-settings"><span class="std std-ref">设置(Settings) API</span></a>.</p>
<p>这些机制将在下面详细介绍。</p>
<div class="section" id="command-line-options">
<h3>1. 命令行选项(Command line options)<a class="headerlink" href="#command-line-options" title="永久链接至标题"></a></h3>
<p>命令行传入的参数具有最高的优先级。
您可以使用command line 选项 <code class="docutils literal"><span class="pre">-s</span></code> (或 <code class="docutils literal"><span class="pre">--set</span></code>) 来覆盖一个(或更多)选项。</p>
<p>样例:</p>
<div class="highlight-sh"><div class="highlight"><pre><span></span>scrapy crawl myspider -s <span class="nv">LOG_FILE</span><span class="o">=</span>scrapy.log
</pre></div>
</div>
</div>
<div class="section" id="project-settings-module">
<h3>2. 项目设定模块(Project settings module)<a class="headerlink" href="#project-settings-module" title="永久链接至标题"></a></h3>
<p>项目设定模块是您Scrapy项目的标准配置文件。
其是获取大多数设定的方法。例如:: <code class="docutils literal"><span class="pre">myproject.settings</span></code> 。</p>
</div>
<div class="section" id="default-settings-per-command">
<h3>3. 命令默认设定(Default settings per-command)<a class="headerlink" href="#default-settings-per-command" title="永久链接至标题"></a></h3>
<p>每个 <a class="reference internal" href="commands.html"><span class="doc">Scrapy tool</span></a> 命令拥有其默认设定，并覆盖了全局默认的设定。
这些设定在命令的类的 <code class="docutils literal"><span class="pre">default_settings</span></code> 属性中指定。</p>
</div>
<div class="section" id="default-global-settings">
<h3>4. 默认全局设定(Default global settings)<a class="headerlink" href="#default-global-settings" title="永久链接至标题"></a></h3>
<p>全局默认设定存储在 <code class="docutils literal"><span class="pre">scrapy.settings.default_settings</span></code> 模块，
并在 <a class="reference internal" href="#topics-settings-ref"><span class="std std-ref">内置设定参考手册</span></a> 部分有所记录。</p>
</div>
</div>
<div class="section" id="how-to-access-settings">
<h2>如何访问设定(How to access settings)<a class="headerlink" href="#how-to-access-settings" title="永久链接至标题"></a></h2>
<p>设定可以通过Crawler的 <a class="reference internal" href="api.html#scrapy.crawler.Crawler.settings" title="scrapy.crawler.Crawler.settings"><code class="xref py py-attr docutils literal"><span class="pre">scrapy.crawler.Crawler.settings</span></code></a>
属性进行访问。其由插件及中间件的 <code class="docutils literal"><span class="pre">from_crawler</span></code> 方法所传入:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">MyExtension</span><span class="p">(</span><span class="nb">object</span><span class="p">):</span>

    <span class="nd">@classmethod</span>
    <span class="k">def</span> <span class="nf">from_crawler</span><span class="p">(</span><span class="bp">cls</span><span class="p">,</span> <span class="n">crawler</span><span class="p">):</span>
        <span class="n">settings</span> <span class="o">=</span> <span class="n">crawler</span><span class="o">.</span><span class="n">settings</span>
        <span class="k">if</span> <span class="n">settings</span><span class="p">[</span><span class="s1">'LOG_ENABLED'</span><span class="p">]:</span>
            <span class="k">print</span> <span class="s2">"log is enabled!"</span>
</pre></div>
</div>
<p>另外，设定可以以字典方式进行访问。不过为了避免类型错误，
通常更希望返回需要的格式。
这可以通过 <a class="reference internal" href="api.html#scrapy.settings.Settings" title="scrapy.settings.Settings"><code class="xref py py-class docutils literal"><span class="pre">Settings</span></code></a> API
提供的方法来实现。</p>
</div>
<div class="section" id="id1">
<h2>设定名字的命名规则<a class="headerlink" href="#id1" title="永久链接至标题"></a></h2>
<p>设定的名字以要配置的组件作为前缀。
例如，一个robots.txt插件的合适设定应该为
<code class="docutils literal"><span class="pre">ROBOTSTXT_ENABLED</span></code>, <code class="docutils literal"><span class="pre">ROBOTSTXT_OBEY</span></code>, <code class="docutils literal"><span class="pre">ROBOTSTXT_CACHEDIR</span></code> 等等。</p>
</div>
<div class="section" id="topics-settings-ref">
<span id="id2"></span><h2>内置设定参考手册<a class="headerlink" href="#topics-settings-ref" title="永久链接至标题"></a></h2>
<p>这里以字母序给出了所有可用的Scrapy设定及其默认值和应用范围。</p>
<p>如果给出可用范围，并绑定了特定的组件，则说明了该设定使用的地方。
这种情况下将给出该组件的模块，通常来说是插件、中间件或pipeline。
同时也意味着为了使设定生效，该组件必须被启用。</p>
<div class="section" id="aws-access-key-id">
<span id="std:setting-AWS_ACCESS_KEY_ID"></span><h3>AWS_ACCESS_KEY_ID<a class="headerlink" href="#aws-access-key-id" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">None</span></code></p>
<p>连接 <a class="reference external" href="http://aws.amazon.com/">Amazon Web services</a> 的AWS access key。
<a class="reference internal" href="feed-exports.html#topics-feed-storage-s3"><span class="std std-ref">S3 feed storage backend</span></a> 中使用.</p>
</div>
<div class="section" id="aws-secret-access-key">
<span id="std:setting-AWS_SECRET_ACCESS_KEY"></span><h3>AWS_SECRET_ACCESS_KEY<a class="headerlink" href="#aws-secret-access-key" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">None</span></code></p>
<p>连接 <a class="reference external" href="http://aws.amazon.com/">Amazon Web services</a>  的AWS secret key。
<a class="reference internal" href="feed-exports.html#topics-feed-storage-s3"><span class="std std-ref">S3 feed storage backend</span></a> 中使用。</p>
</div>
<div class="section" id="bot-name">
<span id="std:setting-BOT_NAME"></span><h3>BOT_NAME<a class="headerlink" href="#bot-name" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">'scrapybot'</span></code></p>
<p>Scrapy项目实现的bot的名字(也未项目名称)。
这将用来构造默认 User-Agent，同时也用来log。</p>
<p>当您使用 <a class="reference internal" href="commands.html#std:command-startproject"><code class="xref std std-command docutils literal"><span class="pre">startproject</span></code></a> 命令创建项目时其也被自动赋值。</p>
</div>
<div class="section" id="concurrent-items">
<span id="std:setting-CONCURRENT_ITEMS"></span><h3>CONCURRENT_ITEMS<a class="headerlink" href="#concurrent-items" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">100</span></code></p>
<p>Item Processor(即 <a class="reference internal" href="item-pipeline.html#topics-item-pipeline"><span class="std std-ref">Item Pipeline</span></a>)
同时处理(每个response的)item的最大值。</p>
</div>
<div class="section" id="concurrent-requests">
<span id="std:setting-CONCURRENT_REQUESTS"></span><h3>CONCURRENT_REQUESTS<a class="headerlink" href="#concurrent-requests" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">16</span></code></p>
<p>Scrapy downloader 并发请求(concurrent requests)的最大值。</p>
</div>
<div class="section" id="concurrent-requests-per-domain">
<span id="std:setting-CONCURRENT_REQUESTS_PER_DOMAIN"></span><h3>CONCURRENT_REQUESTS_PER_DOMAIN<a class="headerlink" href="#concurrent-requests-per-domain" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">8</span></code></p>
<p>对单个网站进行并发请求的最大值。</p>
</div>
<div class="section" id="concurrent-requests-per-ip">
<span id="std:setting-CONCURRENT_REQUESTS_PER_IP"></span><h3>CONCURRENT_REQUESTS_PER_IP<a class="headerlink" href="#concurrent-requests-per-ip" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">0</span></code></p>
<p>对单个IP进行并发请求的最大值。如果非0，则忽略
<a class="reference internal" href="#std:setting-CONCURRENT_REQUESTS_PER_DOMAIN"><code class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_DOMAIN</span></code></a>  设定， 使用该设定。
也就是说，并发限制将针对IP，而不是网站。</p>
<p>该设定也影响 <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_DELAY</span></code></a>:
如果 <a class="reference internal" href="#std:setting-CONCURRENT_REQUESTS_PER_IP"><code class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_IP</span></code></a> 非0，下载延迟应用在IP而不是网站上。</p>
</div>
<div class="section" id="default-item-class">
<span id="std:setting-DEFAULT_ITEM_CLASS"></span><h3>DEFAULT_ITEM_CLASS<a class="headerlink" href="#default-item-class" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">'scrapy.item.Item'</span></code></p>
<p><a class="reference internal" href="shell.html#topics-shell"><span class="std std-ref">the Scrapy shell</span></a> 中实例化item使用的默认类。</p>
</div>
<div class="section" id="default-request-headers">
<span id="std:setting-DEFAULT_REQUEST_HEADERS"></span><h3>DEFAULT_REQUEST_HEADERS<a class="headerlink" href="#default-request-headers" title="永久链接至标题"></a></h3>
<p>默认:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'Accept'</span><span class="p">:</span> <span class="s1">'text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8'</span><span class="p">,</span>
    <span class="s1">'Accept-Language'</span><span class="p">:</span> <span class="s1">'en'</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Scrapy HTTP Request使用的默认header。由
<a class="reference internal" href="downloader-middleware.html#scrapy.contrib.downloadermiddleware.defaultheaders.DefaultHeadersMiddleware" title="scrapy.contrib.downloadermiddleware.defaultheaders.DefaultHeadersMiddleware"><code class="xref py py-class docutils literal"><span class="pre">DefaultHeadersMiddleware</span></code></a>
产生。</p>
</div>
<div class="section" id="depth-limit">
<span id="std:setting-DEPTH_LIMIT"></span><h3>DEPTH_LIMIT<a class="headerlink" href="#depth-limit" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">0</span></code></p>
<p>爬取网站最大允许的深度(depth)值。如果为0，则没有限制。</p>
</div>
<div class="section" id="depth-priority">
<span id="std:setting-DEPTH_PRIORITY"></span><h3>DEPTH_PRIORITY<a class="headerlink" href="#depth-priority" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">0</span></code></p>
<p>整数值。用于根据深度调整request优先级。</p>
<p>如果为0，则不根据深度进行优先级调整。</p>
</div>
<div class="section" id="depth-stats">
<span id="std:setting-DEPTH_STATS"></span><h3>DEPTH_STATS<a class="headerlink" href="#depth-stats" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">True</span></code></p>
<p>是否收集最大深度数据。</p>
</div>
<div class="section" id="depth-stats-verbose">
<span id="std:setting-DEPTH_STATS_VERBOSE"></span><h3>DEPTH_STATS_VERBOSE<a class="headerlink" href="#depth-stats-verbose" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>是否收集详细的深度数据。如果启用，每个深度的请求数将会被收集在数据中。</p>
</div>
<div class="section" id="dnscache-enabled">
<span id="std:setting-DNSCACHE_ENABLED"></span><h3>DNSCACHE_ENABLED<a class="headerlink" href="#dnscache-enabled" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">True</span></code></p>
<p>是否启用DNS内存缓存(DNS in-memory cache)。</p>
</div>
<div class="section" id="downloader">
<span id="std:setting-DOWNLOADER"></span><h3>DOWNLOADER<a class="headerlink" href="#downloader" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">'scrapy.core.downloader.Downloader'</span></code></p>
<p>用于crawl的downloader.</p>
</div>
<div class="section" id="downloader-middlewares">
<span id="std:setting-DOWNLOADER_MIDDLEWARES"></span><h3>DOWNLOADER_MIDDLEWARES<a class="headerlink" href="#downloader-middlewares" title="永久链接至标题"></a></h3>
<p>默认:: <code class="docutils literal"><span class="pre">{}</span></code></p>
<p>保存项目中启用的下载中间件及其顺序的字典。
更多内容请查看 <a class="reference internal" href="downloader-middleware.html#topics-downloader-middleware-setting"><span class="std std-ref">激活下载器中间件</span></a> 。</p>
</div>
<div class="section" id="downloader-middlewares-base">
<span id="std:setting-DOWNLOADER_MIDDLEWARES_BASE"></span><h3>DOWNLOADER_MIDDLEWARES_BASE<a class="headerlink" href="#downloader-middlewares-base" title="永久链接至标题"></a></h3>
<p>默认:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.robotstxt.RobotsTxtMiddleware'</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.httpauth.HttpAuthMiddleware'</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.downloadtimeout.DownloadTimeoutMiddleware'</span><span class="p">:</span> <span class="mi">350</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.useragent.UserAgentMiddleware'</span><span class="p">:</span> <span class="mi">400</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.retry.RetryMiddleware'</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.defaultheaders.DefaultHeadersMiddleware'</span><span class="p">:</span> <span class="mi">550</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.redirect.MetaRefreshMiddleware'</span><span class="p">:</span> <span class="mi">580</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.httpcompression.HttpCompressionMiddleware'</span><span class="p">:</span> <span class="mi">590</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.redirect.RedirectMiddleware'</span><span class="p">:</span> <span class="mi">600</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.cookies.CookiesMiddleware'</span><span class="p">:</span> <span class="mi">700</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.httpproxy.HttpProxyMiddleware'</span><span class="p">:</span> <span class="mi">750</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.chunked.ChunkedTransferMiddleware'</span><span class="p">:</span> <span class="mi">830</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.stats.DownloaderStats'</span><span class="p">:</span> <span class="mi">850</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.downloadermiddleware.httpcache.HttpCacheMiddleware'</span><span class="p">:</span> <span class="mi">900</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>包含Scrapy默认启用的下载中间件的字典。
永远不要在项目中修改该设定，而是修改
<a class="reference internal" href="#std:setting-DOWNLOADER_MIDDLEWARES"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOADER_MIDDLEWARES</span></code></a> 。更多内容请参考
<a class="reference internal" href="downloader-middleware.html#topics-downloader-middleware-setting"><span class="std std-ref">激活下载器中间件</span></a>.</p>
</div>
<div class="section" id="downloader-stats">
<span id="std:setting-DOWNLOADER_STATS"></span><h3>DOWNLOADER_STATS<a class="headerlink" href="#downloader-stats" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">True</span></code></p>
<p>是否收集下载器数据。</p>
</div>
<div class="section" id="download-delay">
<span id="std:setting-DOWNLOAD_DELAY"></span><h3>DOWNLOAD_DELAY<a class="headerlink" href="#download-delay" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">0</span></code></p>
<p>下载器在下载同一个网站下一个页面前需要等待的时间。该选项可以用来限制爬取速度，
减轻服务器压力。同时也支持小数:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">DOWNLOAD_DELAY</span> <span class="o">=</span> <span class="mf">0.25</span>    <span class="c1"># 250 ms of delay</span>
</pre></div>
</div>
<p>该设定影响(默认启用的) <a class="reference internal" href="#std:setting-RANDOMIZE_DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal"><span class="pre">RANDOMIZE_DOWNLOAD_DELAY</span></code></a> 设定。
默认情况下，Scrapy在两个请求间不等待一个固定的值，
而是使用0.5到1.5之间的一个随机值 * <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_DELAY</span></code></a> 的结果作为等待间隔。</p>
<p>当 <a class="reference internal" href="#std:setting-CONCURRENT_REQUESTS_PER_IP"><code class="xref std std-setting docutils literal"><span class="pre">CONCURRENT_REQUESTS_PER_IP</span></code></a> 非0时，延迟针对的是每个ip而不是网站。</p>
<p>另外您可以通过spider的 <code class="docutils literal"><span class="pre">download_delay</span></code> 属性为每个spider设置该设定。</p>
</div>
<div class="section" id="download-handlers">
<span id="std:setting-DOWNLOAD_HANDLERS"></span><h3>DOWNLOAD_HANDLERS<a class="headerlink" href="#download-handlers" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">{}</span></code></p>
<p>保存项目中启用的下载处理器(request downloader handler)的字典。
例子请查看 <cite>DOWNLOAD_HANDLERS_BASE</cite> 。</p>
</div>
<div class="section" id="download-handlers-base">
<span id="std:setting-DOWNLOAD_HANDLERS_BASE"></span><h3>DOWNLOAD_HANDLERS_BASE<a class="headerlink" href="#download-handlers-base" title="永久链接至标题"></a></h3>
<p>默认:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'file'</span><span class="p">:</span> <span class="s1">'scrapy.core.downloader.handlers.file.FileDownloadHandler'</span><span class="p">,</span>
    <span class="s1">'http'</span><span class="p">:</span> <span class="s1">'scrapy.core.downloader.handlers.http.HttpDownloadHandler'</span><span class="p">,</span>
    <span class="s1">'https'</span><span class="p">:</span> <span class="s1">'scrapy.core.downloader.handlers.http.HttpDownloadHandler'</span><span class="p">,</span>
    <span class="s1">'s3'</span><span class="p">:</span> <span class="s1">'scrapy.core.downloader.handlers.s3.S3DownloadHandler'</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>保存项目中默认启用的下载处理器(request downloader handler)的字典。
永远不要在项目中修改该设定，而是修改
<code class="xref std std-setting docutils literal"><span class="pre">DOWNLOADER_HANDLERS</span></code> 。</p>
<p>如果需要关闭上面的下载处理器，您必须在项目中的
<a class="reference internal" href="#std:setting-DOWNLOAD_HANDLERS"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_HANDLERS</span></code></a> 设定中设置该处理器，并为其赋值为 <cite>None</cite> 。
例如，关闭文件下载处理器:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">DOWNLOAD_HANDLERS</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'file'</span><span class="p">:</span> <span class="bp">None</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="download-timeout">
<span id="std:setting-DOWNLOAD_TIMEOUT"></span><h3>DOWNLOAD_TIMEOUT<a class="headerlink" href="#download-timeout" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">180</span></code></p>
<p>下载器超时时间(单位: 秒)。</p>
</div>
<div class="section" id="dupefilter-class">
<span id="std:setting-DUPEFILTER_CLASS"></span><h3>DUPEFILTER_CLASS<a class="headerlink" href="#dupefilter-class" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">'scrapy.dupefilter.RFPDupeFilter'</span></code></p>
<p>用于检测过滤重复请求的类。</p>
<p>默认的 (<code class="docutils literal"><span class="pre">RFPDupeFilter</span></code>) 过滤器基于
<code class="docutils literal"><span class="pre">scrapy.utils.request.request_fingerprint</span></code> 函数生成的请求fingerprint(指纹)。
如果您需要修改检测的方式，您可以继承 <code class="docutils literal"><span class="pre">RFPDupeFilter</span></code>
并覆盖其 <code class="docutils literal"><span class="pre">request_fingerprint</span></code> 方法。
该方法接收 <a class="reference internal" href="request-response.html#scrapy.http.Request" title="scrapy.http.Request"><code class="xref py py-class docutils literal"><span class="pre">Request</span></code></a> 对象并返回其fingerprint(一个字符串)。</p>
</div>
<div class="section" id="dupefilter-debug">
<span id="std:setting-DUPEFILTER_DEBUG"></span><h3>DUPEFILTER_DEBUG<a class="headerlink" href="#dupefilter-debug" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>默认情况下， <code class="docutils literal"><span class="pre">RFPDupeFilter</span></code> 只记录第一次重复的请求。
设置 <a class="reference internal" href="#std:setting-DUPEFILTER_DEBUG"><code class="xref std std-setting docutils literal"><span class="pre">DUPEFILTER_DEBUG</span></code></a> 为 <code class="docutils literal"><span class="pre">True</span></code> 将会使其记录所有重复的requests。</p>
</div>
<div class="section" id="editor">
<span id="std:setting-EDITOR"></span><h3>EDITOR<a class="headerlink" href="#editor" title="永久链接至标题"></a></h3>
<p>默认: <cite>depends on the environment</cite></p>
<p>执行 <a class="reference internal" href="commands.html#std:command-edit"><code class="xref std std-command docutils literal"><span class="pre">edit</span></code></a> 命令编辑spider时使用的编辑器。
其默认为 <code class="docutils literal"><span class="pre">EDITOR</span></code> 环境变量。如果该变量未设置，其默认为 <code class="docutils literal"><span class="pre">vi</span></code> (Unix系统) 或者 IDLE编辑器(Windows)。</p>
</div>
<div class="section" id="extensions">
<span id="std:setting-EXTENSIONS"></span><h3>EXTENSIONS<a class="headerlink" href="#extensions" title="永久链接至标题"></a></h3>
<p>默认:: <code class="docutils literal"><span class="pre">{}</span></code></p>
<p>保存项目中启用的插件及其顺序的字典。</p>
</div>
<div class="section" id="extensions-base">
<span id="std:setting-EXTENSIONS_BASE"></span><h3>EXTENSIONS_BASE<a class="headerlink" href="#extensions-base" title="永久链接至标题"></a></h3>
<p>默认:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'scrapy.contrib.corestats.CoreStats'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.webservice.WebService'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.telnet.TelnetConsole'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.memusage.MemoryUsage'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.memdebug.MemoryDebugger'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.closespider.CloseSpider'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.feedexport.FeedExporter'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.logstats.LogStats'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.spiderstate.SpiderState'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.throttle.AutoThrottle'</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>可用的插件列表。需要注意，有些插件需要通过设定来启用。默认情况下，
该设定包含所有稳定(stable)的内置插件。</p>
<p>更多内容请参考 <a class="reference internal" href="extensions.html#topics-extensions"><span class="std std-ref">extensions用户手册</span></a> 及
<a class="reference internal" href="extensions.html#topics-extensions-ref"><span class="std std-ref">所有可用的插件</span></a> 。</p>
</div>
<div class="section" id="item-pipelines">
<span id="std:setting-ITEM_PIPELINES"></span><h3>ITEM_PIPELINES<a class="headerlink" href="#item-pipelines" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">{}</span></code></p>
<p>保存项目中启用的pipeline及其顺序的字典。该字典默认为空，值(value)任意。
不过值(value)习惯设定在0-1000范围内。</p>
<p>为了兼容性，<a class="reference internal" href="#std:setting-ITEM_PIPELINES"><code class="xref std std-setting docutils literal"><span class="pre">ITEM_PIPELINES</span></code></a> 支持列表，不过已经被废弃了。</p>
<p>样例:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">ITEM_PIPELINES</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">'mybot.pipelines.validate.ValidateMyItem'</span><span class="p">:</span> <span class="mi">300</span><span class="p">,</span>
    <span class="s1">'mybot.pipelines.validate.StoreMyItem'</span><span class="p">:</span> <span class="mi">800</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="item-pipelines-base">
<span id="std:setting-ITEM_PIPELINES_BASE"></span><h3>ITEM_PIPELINES_BASE<a class="headerlink" href="#item-pipelines-base" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">{}</span></code></p>
<p>保存项目中默认启用的pipeline的字典。
永远不要在项目中修改该设定，而是修改
<a class="reference internal" href="#std:setting-ITEM_PIPELINES"><code class="xref std std-setting docutils literal"><span class="pre">ITEM_PIPELINES</span></code></a> 。</p>
</div>
<div class="section" id="log-enabled">
<span id="std:setting-LOG_ENABLED"></span><h3>LOG_ENABLED<a class="headerlink" href="#log-enabled" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">True</span></code></p>
<p>是否启用logging。</p>
</div>
<div class="section" id="log-encoding">
<span id="std:setting-LOG_ENCODING"></span><h3>LOG_ENCODING<a class="headerlink" href="#log-encoding" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">'utf-8'</span></code></p>
<p>logging使用的编码。</p>
</div>
<div class="section" id="log-file">
<span id="std:setting-LOG_FILE"></span><h3>LOG_FILE<a class="headerlink" href="#log-file" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">None</span></code></p>
<p>logging输出的文件名。如果为None，则使用标准错误输出(standard error)。</p>
</div>
<div class="section" id="log-level">
<span id="std:setting-LOG_LEVEL"></span><h3>LOG_LEVEL<a class="headerlink" href="#log-level" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">'DEBUG'</span></code></p>
<p>log的最低级别。可选的级别有: CRITICAL、
ERROR、WARNING、INFO、DEBUG。更多内容请查看 <a class="reference internal" href="logging.html#topics-logging"><span class="std std-ref">Logging</span></a> 。</p>
</div>
<div class="section" id="log-stdout">
<span id="std:setting-LOG_STDOUT"></span><h3>LOG_STDOUT<a class="headerlink" href="#log-stdout" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>如果为 <code class="docutils literal"><span class="pre">True</span></code> ，进程所有的标准输出(及错误)将会被重定向到log中。例如，
执行 <code class="docutils literal"><span class="pre">print</span> <span class="pre">'hello'</span></code> ，其将会在Scrapy log中显示。</p>
</div>
<div class="section" id="memdebug-enabled">
<span id="std:setting-MEMDEBUG_ENABLED"></span><h3>MEMDEBUG_ENABLED<a class="headerlink" href="#memdebug-enabled" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>是否启用内存调试(memory debugging)。</p>
</div>
<div class="section" id="memdebug-notify">
<span id="std:setting-MEMDEBUG_NOTIFY"></span><h3>MEMDEBUG_NOTIFY<a class="headerlink" href="#memdebug-notify" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">[]</span></code></p>
<p>如果该设置不为空，当启用内存调试时将会发送一份内存报告到指定的地址；否则该报告将写到log中。</p>
<p>样例:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">MEMDEBUG_NOTIFY</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'user@example.com'</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="memusage-enabled">
<span id="std:setting-MEMUSAGE_ENABLED"></span><h3>MEMUSAGE_ENABLED<a class="headerlink" href="#memusage-enabled" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></code></p>
<p>是否启用内存使用插件。当Scrapy进程占用的内存超出限制时，该插件将会关闭Scrapy进程，
同时发送email进行通知。</p>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">内存使用扩展(Memory usage extension)</span></a>.</p>
</div>
<div class="section" id="memusage-limit-mb">
<span id="std:setting-MEMUSAGE_LIMIT_MB"></span><h3>MEMUSAGE_LIMIT_MB<a class="headerlink" href="#memusage-limit-mb" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">0</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></code></p>
<p>在关闭Scrapy之前所允许的最大内存数(单位: MB)(如果 MEMUSAGE_ENABLED为True)。
如果为0，将不做限制。</p>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">内存使用扩展(Memory usage extension)</span></a>.</p>
</div>
<div class="section" id="memusage-notify-mail">
<span id="std:setting-MEMUSAGE_NOTIFY_MAIL"></span><h3>MEMUSAGE_NOTIFY_MAIL<a class="headerlink" href="#memusage-notify-mail" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></code></p>
<p>达到内存限制时通知的email列表。</p>
<p>Example:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">MEMUSAGE_NOTIFY_MAIL</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'user@example.com'</span><span class="p">]</span>
</pre></div>
</div>
<p>See <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">内存使用扩展(Memory usage extension)</span></a>.</p>
</div>
<div class="section" id="memusage-report">
<span id="std:setting-MEMUSAGE_REPORT"></span><h3>MEMUSAGE_REPORT<a class="headerlink" href="#memusage-report" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></code></p>
<p>每个spider被关闭时是否发送内存使用报告。</p>
<p>查看 <a class="reference internal" href="extensions.html#topics-extensions-ref-memusage"><span class="std std-ref">内存使用扩展(Memory usage extension)</span></a>.</p>
</div>
<div class="section" id="memusage-warning-mb">
<span id="std:setting-MEMUSAGE_WARNING_MB"></span><h3>MEMUSAGE_WARNING_MB<a class="headerlink" href="#memusage-warning-mb" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">0</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">scrapy.contrib.memusage</span></code></p>
<p>在发送警告email前所允许的最大内存数(单位: MB)(如果 MEMUSAGE_ENABLED为True)。
如果为0，将不发送警告。</p>
</div>
<div class="section" id="newspider-module">
<span id="std:setting-NEWSPIDER_MODULE"></span><h3>NEWSPIDER_MODULE<a class="headerlink" href="#newspider-module" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">''</span></code></p>
<p>使用 <a class="reference internal" href="commands.html#std:command-genspider"><code class="xref std std-command docutils literal"><span class="pre">genspider</span></code></a> 命令创建新spider的模块。</p>
<p>样例:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">NEWSPIDER_MODULE</span> <span class="o">=</span> <span class="s1">'mybot.spiders_dev'</span>
</pre></div>
</div>
</div>
<div class="section" id="randomize-download-delay">
<span id="std:setting-RANDOMIZE_DOWNLOAD_DELAY"></span><h3>RANDOMIZE_DOWNLOAD_DELAY<a class="headerlink" href="#randomize-download-delay" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">True</span></code></p>
<p>如果启用，当从相同的网站获取数据时，Scrapy将会等待一个随机的值
(0.5到1.5之间的一个随机值 * <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_DELAY</span></code></a>)。</p>
<p>该随机值降低了crawler被检测到(接着被block)的机会。某些网站会分析请求，
查找请求之间时间的相似性。</p>
<p>随机的策略与 <a class="reference external" href="http://www.gnu.org/software/wget/manual/wget.html">wget</a> <code class="docutils literal"><span class="pre">--random-wait</span></code> 选项的策略相同。</p>
<p>若 <a class="reference internal" href="#std:setting-DOWNLOAD_DELAY"><code class="xref std std-setting docutils literal"><span class="pre">DOWNLOAD_DELAY</span></code></a> 为0(默认值)，该选项将不起作用。</p>
</div>
<div class="section" id="redirect-max-times">
<span id="std:setting-REDIRECT_MAX_TIMES"></span><h3>REDIRECT_MAX_TIMES<a class="headerlink" href="#redirect-max-times" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">20</span></code></p>
<p>定义request允许重定向的最大次数。超过该限制后该request直接返回获取到的结果。
对某些任务我们使用Firefox默认值。</p>
</div>
<div class="section" id="redirect-max-metarefresh-delay">
<span id="std:setting-REDIRECT_MAX_METAREFRESH_DELAY"></span><h3>REDIRECT_MAX_METAREFRESH_DELAY<a class="headerlink" href="#redirect-max-metarefresh-delay" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">100</span></code></p>
<p>有些网站使用 meta-refresh 重定向到session超时页面，
因此我们限制自动重定向到最大延迟(秒)。
=&gt;有点不肯定:</p>
</div>
<div class="section" id="redirect-priority-adjust">
<span id="std:setting-REDIRECT_PRIORITY_ADJUST"></span><h3>REDIRECT_PRIORITY_ADJUST<a class="headerlink" href="#redirect-priority-adjust" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">+2</span></code></p>
<p>修改重定向请求相对于原始请求的优先级。
负数意味着更多优先级。</p>
</div>
<div class="section" id="robotstxt-obey">
<span id="std:setting-ROBOTSTXT_OBEY"></span><h3>ROBOTSTXT_OBEY<a class="headerlink" href="#robotstxt-obey" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">False</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">scrapy.contrib.downloadermiddleware.robotstxt</span></code></p>
<p>如果启用，Scrapy将会尊重 robots.txt策略。更多内容请查看
<a class="reference internal" href="downloader-middleware.html#topics-dlmw-robots"><span class="std std-ref">RobotsTxtMiddleware</span></a> 。</p>
</div>
<div class="section" id="scheduler">
<span id="std:setting-SCHEDULER"></span><h3>SCHEDULER<a class="headerlink" href="#scheduler" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">'scrapy.core.scheduler.Scheduler'</span></code></p>
<p>用于爬取的调度器。</p>
</div>
<div class="section" id="spider-contracts">
<span id="std:setting-SPIDER_CONTRACTS"></span><h3>SPIDER_CONTRACTS<a class="headerlink" href="#spider-contracts" title="永久链接至标题"></a></h3>
<p>默认:: <code class="docutils literal"><span class="pre">{}</span></code></p>
<p>保存项目中启用用于测试spider的scrapy contract及其顺序的字典。
更多内容请参考 <a class="reference internal" href="contracts.html#topics-contracts"><span class="std std-ref">Spiders Contracts</span></a> 。</p>
</div>
<div class="section" id="spider-contracts-base">
<span id="std:setting-SPIDER_CONTRACTS_BASE"></span><h3>SPIDER_CONTRACTS_BASE<a class="headerlink" href="#spider-contracts-base" title="永久链接至标题"></a></h3>
<p>默认:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'scrapy.contracts.default.UrlContract'</span> <span class="p">:</span> <span class="mi">1</span><span class="p">,</span>
    <span class="s1">'scrapy.contracts.default.ReturnsContract'</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span>
    <span class="s1">'scrapy.contracts.default.ScrapesContract'</span><span class="p">:</span> <span class="mi">3</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>保存项目中默认启用的scrapy contract的字典。
永远不要在项目中修改该设定，而是修改
<a class="reference internal" href="#std:setting-SPIDER_CONTRACTS"><code class="xref std std-setting docutils literal"><span class="pre">SPIDER_CONTRACTS</span></code></a> 。更多内容请参考
<a class="reference internal" href="contracts.html#topics-contracts"><span class="std std-ref">Spiders Contracts</span></a> 。</p>
</div>
<div class="section" id="spider-middlewares">
<span id="std:setting-SPIDER_MIDDLEWARES"></span><h3>SPIDER_MIDDLEWARES<a class="headerlink" href="#spider-middlewares" title="永久链接至标题"></a></h3>
<p>默认:: <code class="docutils literal"><span class="pre">{}</span></code></p>
<p>保存项目中启用的下载中间件及其顺序的字典。
更多内容请参考 <a class="reference internal" href="spider-middleware.html#topics-spider-middleware-setting"><span class="std std-ref">激活spider中间件</span></a> 。</p>
</div>
<div class="section" id="spider-middlewares-base">
<span id="std:setting-SPIDER_MIDDLEWARES_BASE"></span><h3>SPIDER_MIDDLEWARES_BASE<a class="headerlink" href="#spider-middlewares-base" title="永久链接至标题"></a></h3>
<p>默认:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="p">{</span>
    <span class="s1">'scrapy.contrib.spidermiddleware.httperror.HttpErrorMiddleware'</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.spidermiddleware.offsite.OffsiteMiddleware'</span><span class="p">:</span> <span class="mi">500</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.spidermiddleware.referer.RefererMiddleware'</span><span class="p">:</span> <span class="mi">700</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.spidermiddleware.urllength.UrlLengthMiddleware'</span><span class="p">:</span> <span class="mi">800</span><span class="p">,</span>
    <span class="s1">'scrapy.contrib.spidermiddleware.depth.DepthMiddleware'</span><span class="p">:</span> <span class="mi">900</span><span class="p">,</span>
<span class="p">}</span>
</pre></div>
</div>
<p>保存项目中默认启用的spider中间件的字典。
永远不要在项目中修改该设定，而是修改
<a class="reference internal" href="#std:setting-SPIDER_MIDDLEWARES"><code class="xref std std-setting docutils literal"><span class="pre">SPIDER_MIDDLEWARES</span></code></a> 。更多内容请参考
<a class="reference internal" href="spider-middleware.html#topics-spider-middleware-setting"><span class="std std-ref">激活spider中间件</span></a>.</p>
</div>
<div class="section" id="spider-modules">
<span id="std:setting-SPIDER_MODULES"></span><h3>SPIDER_MODULES<a class="headerlink" href="#spider-modules" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">[]</span></code></p>
<p>Scrapy搜索spider的模块列表。</p>
<p>样例:</p>
<div class="highlight-python"><div class="highlight"><pre><span></span><span class="n">SPIDER_MODULES</span> <span class="o">=</span> <span class="p">[</span><span class="s1">'mybot.spiders_prod'</span><span class="p">,</span> <span class="s1">'mybot.spiders_dev'</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="section" id="stats-class">
<span id="std:setting-STATS_CLASS"></span><h3>STATS_CLASS<a class="headerlink" href="#stats-class" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">'scrapy.statscol.MemoryStatsCollector'</span></code></p>
<p>收集数据的类。该类必须实现
<a class="reference internal" href="api.html#topics-api-stats"><span class="std std-ref">状态收集器(Stats Collector) API</span></a>.</p>
</div>
<div class="section" id="stats-dump">
<span id="std:setting-STATS_DUMP"></span><h3>STATS_DUMP<a class="headerlink" href="#stats-dump" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">True</span></code></p>
<p>当spider结束时dump <a class="reference internal" href="stats.html#topics-stats"><span class="std std-ref">Scrapy状态数据</span></a> (到Scrapy log中)。</p>
<p>更多内容请查看 <a class="reference internal" href="stats.html#topics-stats"><span class="std std-ref">数据收集(Stats Collection)</span></a> 。</p>
</div>
<div class="section" id="statsmailer-rcpts">
<span id="std:setting-STATSMAILER_RCPTS"></span><h3>STATSMAILER_RCPTS<a class="headerlink" href="#statsmailer-rcpts" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">[]</span></code> (空list)</p>
<p>spider完成爬取后发送Scrapy数据。更多内容请查看
<code class="xref py py-class docutils literal"><span class="pre">StatsMailer</span></code> 。</p>
</div>
<div class="section" id="telnetconsole-enabled">
<span id="std:setting-TELNETCONSOLE_ENABLED"></span><h3>TELNETCONSOLE_ENABLED<a class="headerlink" href="#telnetconsole-enabled" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">True</span></code></p>
<p>表明 <a class="reference internal" href="telnetconsole.html#topics-telnetconsole"><span class="std std-ref">telnet 终端</span></a> (及其插件)是否启用的布尔值。</p>
</div>
<div class="section" id="telnetconsole-port">
<span id="std:setting-TELNETCONSOLE_PORT"></span><h3>TELNETCONSOLE_PORT<a class="headerlink" href="#telnetconsole-port" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">[6023,</span> <span class="pre">6073]</span></code></p>
<p>telnet终端使用的端口范围。如果设置为 <code class="docutils literal"><span class="pre">None</span></code> 或 <code class="docutils literal"><span class="pre">0</span></code> ，
则使用动态分配的端口。更多内容请查看
<a class="reference internal" href="telnetconsole.html#topics-telnetconsole"><span class="std std-ref">Telnet终端(Telnet Console)</span></a> 。</p>
</div>
<div class="section" id="templates-dir">
<span id="std:setting-TEMPLATES_DIR"></span><h3>TEMPLATES_DIR<a class="headerlink" href="#templates-dir" title="永久链接至标题"></a></h3>
<p>默认:  scrapy模块内部的 <code class="docutils literal"><span class="pre">templates</span></code></p>
<p>使用 <a class="reference internal" href="commands.html#std:command-startproject"><code class="xref std std-command docutils literal"><span class="pre">startproject</span></code></a> 命令创建项目时查找模板的目录。</p>
</div>
<div class="section" id="urllength-limit">
<span id="std:setting-URLLENGTH_LIMIT"></span><h3>URLLENGTH_LIMIT<a class="headerlink" href="#urllength-limit" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">2083</span></code></p>
<p>Scope: <code class="docutils literal"><span class="pre">contrib.spidermiddleware.urllength</span></code></p>
<p>爬取URL的最大长度。更多关于该设定的默认值信息请查看:
<a class="reference external" href="http://www.boutell.com/newfaq/misc/urllength.html">http://www.boutell.com/newfaq/misc/urllength.html</a></p>
</div>
<div class="section" id="user-agent">
<span id="std:setting-USER_AGENT"></span><h3>USER_AGENT<a class="headerlink" href="#user-agent" title="永久链接至标题"></a></h3>
<p>默认: <code class="docutils literal"><span class="pre">"Scrapy/VERSION</span> <span class="pre">(+http://scrapy.org)"</span></code></p>
<p>爬取的默认User-Agent，除非被覆盖。</p>
</div>
</div>
</div>
<h2>
            讨论
            <a class="headerlink" href="#discuss" title="永久链接至标题"></a>
</h2>
<div id="disqus_thread"></div>
</div>
<div class="articleComments">
</div>
</div>
    
</body></html>
